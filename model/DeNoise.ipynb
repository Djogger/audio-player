{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Di6aV1s3pYkS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pystoi.stoi import stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, noisy_dir, clean_dir, sample_rate=16000, max_length=50000):\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.noisy_files = sorted(os.listdir(noisy_dir))\n",
    "        self.clean_files = sorted(os.listdir(clean_dir))\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        noisy_path = os.path.join(self.noisy_dir, self.noisy_files[idx])\n",
    "        clean_path = os.path.join(self.clean_dir, self.clean_files[idx])\n",
    "\n",
    "        noisy_waveform, _ = torchaudio.load(noisy_path)\n",
    "        clean_waveform, _ = torchaudio.load(clean_path)\n",
    "\n",
    "        if self.max_length is not None:\n",
    "            noisy_waveform = self._fix_length(noisy_waveform, self.max_length)\n",
    "            clean_waveform = self._fix_length(clean_waveform, self.max_length)\n",
    "\n",
    "        return noisy_waveform.squeeze(0), clean_waveform.squeeze(0)\n",
    "\n",
    "    def _fix_length(self, waveform, max_length):\n",
    "        length = waveform.shape[-1]\n",
    "        if length > max_length:\n",
    "            return waveform[:, :max_length]\n",
    "        elif length < max_length:\n",
    "            pad_amount = max_length - length\n",
    "            return torch.nn.functional.pad(waveform, (0, pad_amount))\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_files_path = \"C:\\\\Users\\\\Ksenia\\\\Desktop\\\\train_data\\\\train_combined\"\n",
    "clean_files_path = \"C:\\\\Users\\\\Ksenia\\\\Desktop\\\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(noisy_files_path, clean_files_path)\n",
    "#val_dataset = AudioDataset(noisy_files_val, clean_files_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mQ71qG6Hplvg"
   },
   "outputs": [],
   "source": [
    "class SincConv(nn.Module):\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate):\n",
    "        super(SincConv, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.band_pass = nn.Parameter(torch.Tensor(out_channels, 2))\n",
    "        self.init_kernels()\n",
    "\n",
    "    def init_kernels(self):\n",
    "        self.band_pass.data[:, 0] = torch.linspace(30, 300, self.out_channels)\n",
    "        self.band_pass.data[:, 1] = torch.linspace(3000, 8000, self.out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        filters = self.create_filters().to(x.device)\n",
    "        return nn.functional.conv1d(x, filters, stride=1, padding=self.kernel_size // 2)\n",
    "\n",
    "    def create_filters(self):\n",
    "        filters = torch.zeros(self.out_channels, 1, self.kernel_size)\n",
    "        for i in range(self.out_channels):\n",
    "            low, high = self.band_pass[i]\n",
    "            filters[i, 0, :] = self.sinc_filter(low, high)\n",
    "        return filters\n",
    "\n",
    "    def sinc_filter(self, low, high):\n",
    "        t = torch.linspace(-self.kernel_size // 2, self.kernel_size // 2, self.kernel_size)\n",
    "        t = t.detach().numpy()\n",
    "        sinc_filter = (np.sin(2 * np.pi * high.item() * t) - np.sin(2 * np.pi * low.item() * t)) / (np.pi * t)\n",
    "        sinc_filter[t == 0] = 2 * (high.item() - low.item())\n",
    "        window = 0.54 - 0.46 * np.cos(2 * np.pi * np.arange(self.kernel_size) / (self.kernel_size - 1))\n",
    "        return torch.from_numpy(sinc_filter * window).float()\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class DeNoise(nn.Module):\n",
    "    def __init__(self, kernel_size, sample_rate, resnet_blocks, sinc_out_channels=10, gru_hidden_size=128, gru_layers=1):\n",
    "        super(DeNoise, self).__init__()\n",
    "        self.sinc_conv = SincConv(sinc_out_channels, kernel_size, sample_rate)\n",
    "        self.resnet_blocks = nn.Sequential(\n",
    "            *[BasicBlock(sinc_out_channels, sinc_out_channels) for _ in range(resnet_blocks)]\n",
    "        )\n",
    "        self.gru = nn.GRU(input_size=sinc_out_channels, hidden_size=gru_hidden_size, num_layers=gru_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(gru_hidden_size * 2, sinc_out_channels)\n",
    "        self.output_conv = nn.Conv1d(sinc_out_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sinc_conv(x)\n",
    "        x = self.resnet_blocks(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        gru_out, _ = self.gru(x)\n",
    "        x = self.fc(gru_out)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.output_conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoi(clean_audio, enhanced_audio, sample_rate):\n",
    "    min_len = min(clean_audio.size(1), enhanced_audio.size(1))\n",
    "    clean_audio = clean_audio[:, :min_len].cpu().detach().numpy().squeeze().reshape(-1, 1)\n",
    "    enhanced_audio = enhanced_audio[:, :min_len].cpu().detach().numpy().squeeze().reshape(-1, 1)\n",
    "    score = stoi(clean_audio, enhanced_audio, sample_rate, extended=False)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=20, sample_rate=16000):\n",
    "    model.to(device)\n",
    "    total_train_stoi_score = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_batches = 0\n",
    "        \n",
    "        for i, (noisy, clean) in enumerate(tqdm(train_loader, desc=f'Training epoch {epoch+1}')):\n",
    "            noisy = noisy.unsqueeze(1).to(device)\n",
    "            clean = clean.unsqueeze(1).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(noisy)\n",
    "            \n",
    "            loss = criterion(outputs, clean)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "            if i % 31 == 0:\n",
    "                model.eval()\n",
    "                train_stoi_score = compute_stoi(clean, outputs, sample_rate)\n",
    "                total_train_stoi_score += train_stoi_score\n",
    "                model.train()\n",
    "    \n",
    "        avg_train_stoi_score = total_train_stoi_score / len(train_loader)\n",
    "\n",
    "        '''model.eval()\n",
    "        total_stoi_score = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                noisy_audio, clean_audio = batch\n",
    "                out = model(noisy_audio)\n",
    "                stoi_score = compute_stoi(clean_audio, out, sample_rate)\n",
    "                total_stoi_score += stoi_score'''\n",
    "    \n",
    "        #avg_val_stoi_score = total_stoi_score / len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train STOI Score: {avg_train_stoi_score:.4f},\") #Val STOI Score: {avg_val_stoi_score:.4f}\")\n",
    "        \n",
    "        epoch_loss = running_loss / total_batches\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeNoise(kernel_size=101, sample_rate=16000, resnet_blocks=3, sinc_out_channels=10, gru_hidden_size=128, gru_layers=2)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, criterion, optimizer, num_epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path, sr=16000):\n",
    "    audio, sample_rate = librosa.load(file_path, sr=sr)\n",
    "    return audio, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio, sample_rate, target_length=16000):\n",
    "    audio_tensor = torch.tensor(audio).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    if audio_tensor.size(2) < target_length:\n",
    "        audio_tensor = torch.nn.functional.pad(audio_tensor, (0, target_length - audio_tensor.size(2)))\n",
    "    \n",
    "    return audio_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_audio(model, noisy_audio):\n",
    "    with torch.no_grad():\n",
    "        clean_audio = model(noisy_audio)\n",
    "        clean_audio = clean_audio.squeeze().cpu().numpy()\n",
    "    return clean_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "def save_audio(file_path, audio, sample_rate):\n",
    "    sf.write(file_path, audio, sample_rate)\n",
    "\n",
    "noisy_audio_path = 'C:\\\\Users\\\\Ksenia\\\\Desktop\\\\test.wav'\n",
    "output_path = 'denoised_output.wav'\n",
    "\n",
    "audio, sr = load_audio(noisy_audio_path)\n",
    "preprocessed_audio = preprocess_audio(audio, sr)\n",
    "clean_audio = denoise_audio(model, preprocessed_audio)\n",
    "save_audio(output_path, clean_audio, sr)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
